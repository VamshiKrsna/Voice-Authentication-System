{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research around Voice Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pyaudio\n",
    "import wave\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 22050\n",
    "duration = 5 \n",
    "num_mfcc = 13\n",
    "num_recordings = 3\n",
    "model_path = \"voice_auth_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(filename, duration=duration, sample_rate=sample_rate):\n",
    "    \"\"\"Record audio from the microphone and save to a file.\"\"\"\n",
    "    chunk = 1024\n",
    "    format = pyaudio.paInt16\n",
    "    channels = 1\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=format, channels=channels, rate=sample_rate, input=True, frames_per_buffer=chunk)\n",
    "\n",
    "    print(f\"Recording: {filename}\")\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(0, int(sample_rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(format))\n",
    "    wf.setframerate(sample_rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    \"\"\"Extract MFCC features from an audio file.\"\"\"\n",
    "    audio, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc)\n",
    "    return np.mean(mfccs.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(features):\n",
    "    \"\"\"Train a GMM model on the extracted features.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    model = GaussianMixture(n_components=1, covariance_type='diag', max_iter=200, random_state=42)\n",
    "    model.fit(features_scaled)\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, scaler, path=model_path):\n",
    "    \"\"\"Save the trained model and scaler to a file.\"\"\"\n",
    "    import pickle\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump((model, scaler), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path=model_path):\n",
    "    \"\"\"Load the trained model and scaler from a file.\"\"\"\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_voice(file_path, model, scaler):\n",
    "    \"\"\"Authenticate a voice sample against the trained model.\"\"\"\n",
    "    features = extract_features(file_path)\n",
    "    features_scaled = scaler.transform([features])\n",
    "    score = model.score(features_scaled)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording: voice_sample_0.wav\n",
      "Recording: voice_sample_1.wav\n",
      "Recording: voice_sample_2.wav\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Record initial samples for training\n",
    "    training_files = [f\"voice_sample_{i}.wav\" for i in range(num_recordings)]\n",
    "    for file in training_files:\n",
    "        record_audio(file)\n",
    "\n",
    "    # Extract features and train model\n",
    "    features = np.array([extract_features(file) for file in training_files])\n",
    "    model, scaler = train_model(features)\n",
    "    save_model(model, scaler)\n",
    "\n",
    "    # Authenticate a new voice sample\n",
    "    test_file = \"test_voice_sample.wav\"\n",
    "    record_audio(test_file)\n",
    "    model, scaler = load_model()\n",
    "    score = authenticate_voice(test_file, model, scaler)\n",
    "\n",
    "    # Threshold for authentication (this is a simple example, adjust as needed)\n",
    "    threshold = -50\n",
    "    if score > threshold:\n",
    "        print(\"Authentication successful: Same person\")\n",
    "    else:\n",
    "        print(\"Authentication failed: Different person\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
